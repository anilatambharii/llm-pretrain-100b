# llm-pretrain-100b
LLM Pretraining Framework (100B+ Params): Megatron-LM + DeepSpeed + FSDP. Open-source, HPC-ready system with tiny GPT simulation, distributed training, tokenizer tools, dataset pipelines, and deployment scripts for Slurm, AWS, Azure, and Docker.
